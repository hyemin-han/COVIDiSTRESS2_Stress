# set the current directory
here::i_am('README.md')
here::here()
# load data
dat <- import(here("_cleandata/Final_COVIDiSTRESS_Vol2_cleaned.csv"))
colnames(dat)
vars <- colnames(dat)[80:87]
vars
test <- dat[,vars]
library(EFAtools)
N_FACTORS(test)
test1<-dat[dat$UserLanguage=='EN',vars]
N_FACTORS(test1)
N_FACTORS(test1,method='ML')
EFA_SPSS
EFA(test1,n_factors=1)
EFA(test1,n_factors=1,type='SPSS')
EFA(test1,n_factors=2,type='SPSS')
EFA(test1,n_factors=2,type='SPSS',rotation='promax')
EFA(test1,n_factors=2,type='SPSS',rotation='varimax')
N_FACTORS(test1,method='ML')
EFA(test1,n_factors=1,type='SPSS')
EFA(test1,n_factors=2,type='SPSS')
N_FACTORS(test1[,-7],method='ML')
EFA(test1[,-7])
EFA(test1[,-7],n_factors=1)
# do correction
library(BayesFactor)
library("oro.nifti")
correct_scale<-function(filename_mask = 'mask.nii'){
# read mask file
MaskImg <- readNIfTI(filename_mask)
MaskImgData = oro.nifti::img_data(MaskImg)
# get mask size image
X <- dim(MaskImg)[1]
Y <- dim(MaskImg)[2]
Z <- dim(MaskImg)[3]
# let's count non-zero and non-nan voxel number
count <- 0
for (i in 1:X){
for (j in 1:Y){
for (k in 1:Z){
if ((MaskImgData[i,j,k] != 0) && !(is.nan(MaskImgData[i,j,k])) ){
# non zero and non nan -> count
count <- count + 1
}
}
}
}
# get combination (to find the # of comparison groups)
# find m where mC2 = total voxel number
# start from 2
config_scale <- .707
config_alpha <- .05
now <- 2
while(1){
# calculate current combination
combination <- now * (now-1)/2
# combination >= count (non-zero non-nan voxel #?)
if (combination >= count){
break
}
# the goal not achieved, then, increase 1
now <- now + 1
}
# finalize group number
Group <- now
# then, p(H01) = p(H0)^(2/m) where m = Group
# calculate the corrected threshold value
# .95 ^ (2/Group)
corr_p <- (1-config_alpha)^(2/Group)
# time to look for Cauchy distribution scale SCALE_NEW that satisfies
# pcauchy(qcauchy(.95,scale=.707), SCALE_NEW) = corr_p
default_point <- qcauchy((1-config_alpha),scale=config_scale)
# set desired precision
# default = (1-corr_p) / 10
precision <- (1-corr_p) / 10
# starting from the default scale .707
scale_default <- config_scale
scale_current <- scale_default
scale_previous <- scale_default
trial <- 1
while(1)
{
# until the precision is achieved...
# if first trial,
if (trial == 1)
{
# starting from the half of the default scale
scale_current <- scale_default / 2.0
# calculate the current culumative pdf at default_point
current_cpdf <- pcauchy(default_point, scale= scale_current)
# calculate difference
diff <- abs(corr_p - current_cpdf)
# diff <= precision?
if (diff <= precision){
# stop here
break
}
# if not, trial <- trial + 1
trial <- trial + 1
# and also find the dirrection
if ((corr_p - current_cpdf) > 0)
{
# scale_current should be decreased, so right direction
direction <- -1
}
else
{
# scale_current should be increased, so let's tweak it
direction <- 1
}
}
else{
# if not the first trial...
# find the distance between current and previous scale
distance <- abs(scale_current - scale_previous)
# then, set the current scale as start_point + distance /2 * direction
# also, update the previous scale
scale_previous <- scale_current
scale_current <- scale_current + distance / 2.0 * direction
# calculate the current culumative pdf at default_point
current_cpdf <- pcauchy(default_point,scale= scale_current)
# calculate difference
diff <- abs(corr_p - current_cpdf)
# diff <= precision?
if (diff <= precision){
# stop here
break
}
# if not, trial <- trial + 1
trial <- trial + 1
# and also find the dirrection
if ((corr_p - current_cpdf) > 0)
{
# scale_current should be decreased, so right direction
direction <- -1
}
else
{
# scale_current should be increased, so let's tweak it
direction <- 1
}
}
}
# found current scale!
# let's use this scale for cauchy prior distribution
return(scale_current)
}
adjust_cauchy_scale(4.7854359796610275,1.5598297650412472,0.05145979448703311)
# do correction
library(BayesFactor)
library("oro.nifti")
# correcting Cauchy prior based on effect size and proportion of predicted positives
# inputs: contrast, noise (standard deviation, etc.), proportion of positives, percentile (e.g., .9? .95?)
# precision (default = 1e-9), max iterations (default = 10000)
# output: corrected Cauchy prior
# function to find
f <- function(x){
# pcauchy
# ES should be defined globally
# percentile should also be defined globally
fx<-pcauchy(ES,scale=x)-percentile
return(c(fx))
}
adjust_cauchy_scale<-function(contrast, noise, proportion, percentile = .9, precision = 1e-9, max_iter=10000)
{
# calculate average ES
ES <<- contrast / noise * proportion
# put percentile in global
percentile<<-percentile
# numerically estimate scale
# from 0 to 100, start from 50
now <- 50
from <- 0
to <- 100
iteration<-0
while(1){
iteration <- iteration + 1
# calculate pcauchy with the current scale
current <- f(now)
# difference?
if (abs(current) <= precision){
# within the boundary of the allowed precision. Stop
break
}
# if not, then move for 1/2
# if difference < 0, it indicates that the scale should increase
if (current >0){
from<-now
now <- (now + to)/2
}else{
# else, then the scale should decrease
to<-now
now <- (from + now)/2
}
# if iteration > max_iteration, stop
if (iteration >= max_iter){
break
}
}
# return iteration # and result
# if convergence failed then return -1
if (iteration >= max_iter){
return (-1)
}else{
return(now)
}
}
correct_scale<-function(filename_mask = 'mask.nii'){
# read mask file
MaskImg <- readNIfTI(filename_mask)
MaskImgData = oro.nifti::img_data(MaskImg)
# get mask size image
X <- dim(MaskImg)[1]
Y <- dim(MaskImg)[2]
Z <- dim(MaskImg)[3]
# let's count non-zero and non-nan voxel number
count <- 0
for (i in 1:X){
for (j in 1:Y){
for (k in 1:Z){
if ((MaskImgData[i,j,k] != 0) && !(is.nan(MaskImgData[i,j,k])) ){
# non zero and non nan -> count
count <- count + 1
}
}
}
}
# get combination (to find the # of comparison groups)
# find m where mC2 = total voxel number
# start from 2
config_scale <- .707
config_alpha <- .05
now <- 2
while(1){
# calculate current combination
combination <- now * (now-1)/2
# combination >= count (non-zero non-nan voxel #?)
if (combination >= count){
break
}
# the goal not achieved, then, increase 1
now <- now + 1
}
# finalize group number
Group <- now
# then, p(H01) = p(H0)^(2/m) where m = Group
# calculate the corrected threshold value
# .95 ^ (2/Group)
corr_p <- (1-config_alpha)^(2/Group)
# time to look for Cauchy distribution scale SCALE_NEW that satisfies
# pcauchy(qcauchy(.95,scale=.707), SCALE_NEW) = corr_p
default_point <- qcauchy((1-config_alpha),scale=config_scale)
# set desired precision
# default = (1-corr_p) / 10
precision <- (1-corr_p) / 10
# starting from the default scale .707
scale_default <- config_scale
scale_current <- scale_default
scale_previous <- scale_default
trial <- 1
while(1)
{
# until the precision is achieved...
# if first trial,
if (trial == 1)
{
# starting from the half of the default scale
scale_current <- scale_default / 2.0
# calculate the current culumative pdf at default_point
current_cpdf <- pcauchy(default_point, scale= scale_current)
# calculate difference
diff <- abs(corr_p - current_cpdf)
# diff <= precision?
if (diff <= precision){
# stop here
break
}
# if not, trial <- trial + 1
trial <- trial + 1
# and also find the dirrection
if ((corr_p - current_cpdf) > 0)
{
# scale_current should be decreased, so right direction
direction <- -1
}
else
{
# scale_current should be increased, so let's tweak it
direction <- 1
}
}
else{
# if not the first trial...
# find the distance between current and previous scale
distance <- abs(scale_current - scale_previous)
# then, set the current scale as start_point + distance /2 * direction
# also, update the previous scale
scale_previous <- scale_current
scale_current <- scale_current + distance / 2.0 * direction
# calculate the current culumative pdf at default_point
current_cpdf <- pcauchy(default_point,scale= scale_current)
# calculate difference
diff <- abs(corr_p - current_cpdf)
# diff <= precision?
if (diff <= precision){
# stop here
break
}
# if not, trial <- trial + 1
trial <- trial + 1
# and also find the dirrection
if ((corr_p - current_cpdf) > 0)
{
# scale_current should be decreased, so right direction
direction <- -1
}
else
{
# scale_current should be increased, so let's tweak it
direction <- 1
}
}
}
# found current scale!
# let's use this scale for cauchy prior distribution
return(scale_current)
}
adjust_cauchy_scale(4.7854359796610275,1.5598297650412472,0.05145979448703311)
adjust_cauchy_scale(2.337460017950926,0.09000875833726335,0.20115387840324436)
adjust_cauchy_scale(5.2238155142807825,2.337460017950926,0.09000875833726335)
setwd("~/Documents/GitHub/COVIDiSTRESS2_Stress/H3a")
load("~/Documents/GitHub/COVIDiSTRESS2_Stress/H3a/stress_H3a.RData")
log(pss.21$bf[1])
EMAtools::lme.dscore(lmer.pss.1,data.filtered,'lme4')
# hypothesis testing
library(lmerTest)
library(brms)
library(EMAtools)
library(sjstats)
# ICC calculation
sjstats::icc(lmer.pss.1)
# ICC calculation
lmer.pss.2 <- lmer (pss ~ primary_stressor_avg + gender + education + work_location + age+
SSS_faml+ relationship_status+
(1+primary_stressor_avg|residing_country),
data=data.filtered)
sjstats::icc(lmer.pss.2)
performance::icc(lmer.pss.2)
res.21
hypothesis(res.1,'primary_stressor_avg < 0')
hypothesis(res.2,'primary_stressor_avg < 0')
# effect size
lmer.res.1 <- lmer (resilience ~ primary_stressor_avg + gender + education + work_location + age+
SSS_faml+ relationship_status+
(1|residing_country),
data=data.filtered)
# icc test
lmer.res.2 <- lmer (resilience ~ primary_stressor_avg + gender + education + work_location + age+
SSS_faml+ relationship_status+
(1+primary_stressor_avg|residing_country),
data=data.filtered)
performance::icc(lmer.res.2)
res.00 <- brms::brm(resilience ~ gender + education + work_location + age+
SSS_faml+ relationship_status
data=data.filtered, family = gaussian(),
res.00 <- brms::brm(resilience ~ gender + education + work_location + age+
SSS_faml + relationship_status,
data=data.filtered, family = gaussian(),
cores=4,chains=4, save_pars = save_pars(all = T),
sample_prior ='yes', seed=1660415,prior=prior.coef)
bayes_factor(res.2,res.00)
setwd("~/Documents/GitHub/COVIDiSTRESS2_Stress/H3b")
load("~/Documents/GitHub/COVIDiSTRESS2_Stress/H3b/Vaccine_H3bs.RData")
bf.int <- bayes_factor(pss.int,pss.2)
bf.int
bf.gender
bf.edu
bf.ocu
bf.gender.edu
# gender / education
pss.int.gender.edu <- brms::brm(pss ~ gender*secondary + work_location + age+
SSS_faml+ relationship_status+ secondary*education+
occupation+
(1+secondary|residing_country),
data=data.filtered, family = gaussian(),
cores=4,chains=4, save_pars = save_pars(all = T),
sample_prior ='yes', seed=1660415,prior=prior.coef)
bf.gender.edu <- bayes_factor(pss.int.edu,pss.2)
bf.gender.edu
# gender / occupation
pss.int.gender.occu <- brms::brm(pss ~ gender*secondary + work_location + age+
SSS_faml+ relationship_status+ education+
occupation*secondary+
(1+secondary|residing_country),
data=data.filtered, family = gaussian(),
cores=4,chains=4, save_pars = save_pars(all = T),
sample_prior ='yes', seed=1660415,prior=prior.coef)
bf.gender.occu <- bayes_factor(pss.int.edu,pss.2)
bf.gender.occu
pss.int.gender.occu
bf.gender.occu <- bayes_factor(pss.int.gender.occu,pss.2)
bf.gender.occu
bf.gender.edu <- bayes_factor(pss.int.gender.edu,pss.2)
pss.int.gender.edu
bf.gender.edu
pss.int.edu.occu <- brms::brm(pss ~ gender + work_location + age+
SSS_faml+ relationship_status+ education*secondary+
occupation*secondary+
(1+secondary|residing_country),
data=data.filtered, family = gaussian(),
cores=4,chains=4, save_pars = save_pars(all = T),
sample_prior ='yes', seed=1660415,prior=prior.coef)
bf.edu.occu <- bayes_factor(pss.int.edu.occu,pss.2)
bf.edu.occu
save.image("~/Documents/GitHub/COVIDiSTRESS2_Stress/H3b/Vaccine_H3bs.RData")
pss.21
res.21
AIC
BIC(freq.pss.2,freq.pss.int)
# ICC
performance::icc(freq.pss.2)
res.int.1 <- bayes_factor(res.int,res.1)
res.int.1
res.gender.1 <- bayes_factor(res.int.gender,res.1)
res.gender.1
# gender
res.int.gender <- brms::brm(resilience ~ secondary*gender + education + work_location + age+
SSS_faml+ relationship_status+ occupation+
(1|residing_country),
data=data.filtered, family = gaussian(),
cores=4,chains=4, save_pars = save_pars(all = T),
sample_prior ='yes', seed=1660415,prior=prior.coef)
res.gender.1 <- bayes_factor(res.int.gender,res.1)
res.gender.1
# education
res.int.edu<- brms::brm(resilience ~ gender + secondary*education + work_location + age+
SSS_faml+ relationship_status+ occupation+
(1|residing_country),
data=data.filtered, family = gaussian(),
cores=4,chains=4, save_pars = save_pars(all = T),
sample_prior ='yes', seed=1660415,prior=prior.coef)
res.int.edu
res.edu.1 <- bayes_factor(res.int.gender,res.1)
res.edu.1
res.edu.1 <- bayes_factor(res.int.edu,res.1)
res.edu.1
# occupation
res.int.occu<- brms::brm(resilience ~ gender + education + work_location + age+
SSS_faml+ relationship_status+ occupation*secondary+
(1|residing_country),
data=data.filtered, family = gaussian(),
cores=4,chains=4, save_pars = save_pars(all = T),
sample_prior ='yes', seed=1660415,prior=prior.coef)
res.occu.1 <- bayes_factor(res.int.occu,res.1)
# occupation
res.int.occu<- brms::brm(resilience ~ gender + education + work_location + age+
SSS_faml+ relationship_status+ occupation*secondary+
(1|residing_country),
data=data.filtered, family = gaussian(),
cores=4,chains=4, save_pars = save_pars(all = T),
sample_prior ='yes', seed=1660415,prior=prior.coef)
res.occu.1
res.int.occu
res.occu.1
save.image("~/Documents/GitHub/COVIDiSTRESS2_Stress/H3b/Vaccine_H3bs.RData")
res.int.gender.edu <- brms::brm(resilience ~ secondary*gender + secondary*education + work_location + age+
SSS_faml+ relationship_status+ occupation+
(1|residing_country),
data=data.filtered, family = gaussian(),
cores=4,chains=4, save_pars = save_pars(all = T),
sample_prior ='yes', seed=1660415,prior=prior.coef)
res.gender.edu.1 <- bayes_factor(res.int.gender.edu,res.1)
res.gender.edu.1
res.int.gender.occu <- brms::brm(resilience ~ secondary*gender + education + work_location + age+
SSS_faml+ relationship_status+ secondary*occupation+
(1|residing_country),
data=data.filtered, family = gaussian(),
cores=4,chains=4, save_pars = save_pars(all = T),
sample_prior ='yes', seed=1660415,prior=prior.coef)
res.gender.occu.1 <- bayes_factor(res.int.gender.occu,res.1)
res.gender.occu.1
res.int.edu.occu <- brms::brm(resilience ~ gender + secondary*education + work_location + age+
SSS_faml+ relationship_status+ secondary*occupation+
(1|residing_country),
data=data.filtered, family = gaussian(),
cores=4,chains=4, save_pars = save_pars(all = T),
sample_prior ='yes', seed=1660415,prior=prior.coef)
res.edu.occu.1 <- bayes_factor(res.int.edu.occu,res.1)
res.edu.occu.1
# frequentist and icc
freq.res.1 <- lmer(resilience ~ secondary+ gender + education + work_location + age+
SSS_faml+ relationship_status+
(1|residing_country),data=data.filtered)
freq.res.int <- lmer(resilience ~ secondary*gender + secondary*education + work_location + age+
SSS_faml+ relationship_status+ secondary*occupation+
(1|residing_country),data=data.filtered)
BIC(freq.res.1,freq.res.int)
AIC(freq.res.1,freq.res.int)
AIC(freq.res.1,freq.pss.int)
# icc
performance::icc(freq.res.1)
freq.res.00 <- lmer(resilience ~ secondary+ gender + education + work_location + age+
SSS_faml+ relationship_status),data=data.filtered)
freq.res.00 <- lmer(resilience ~ secondary+ gender + education + work_location + age+
SSS_faml+ relationship_status,data=data.filtered)
freq.res.00 <- lm(resilience ~ secondary+ gender + education + work_location + age+
SSS_faml+ relationship_status,data=data.filtered)
BIC(freq.res.00,freq.res.1)
AIC(freq.res.00,freq.res.1)
save.image(file='Vaccine_H3bs.RData')
