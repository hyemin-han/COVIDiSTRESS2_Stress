% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Stress\_MI.R},
  pdfauthor={hhan19},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi

\title{Stress\_MI.R}
\author{hhan19}
\date{2022-04-15}

\begin{document}
\maketitle

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(psych)}
\FunctionTok{library}\NormalTok{(lavaan)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## This is lavaan 0.6-10
## lavaan is FREE software! Please report any bugs.
\end{verbatim}

\begin{verbatim}
## 
## Attaching package: 'lavaan'
\end{verbatim}

\begin{verbatim}
## The following object is masked from 'package:psych':
## 
##     cor2cov
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(sirt)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## - sirt 3.11-21 (2021-12-09 11:21:10)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(MASS)}

\CommentTok{\# function for factor score adjustment}
\NormalTok{aligned.factor.scores }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(lambda,nu,y)\{}
  \CommentTok{\# calculate inverse matrix}
\NormalTok{  lambda1 }\OtherTok{\textless{}{-}} \FunctionTok{ginv}\NormalTok{((lambda))}
  \CommentTok{\# create matrix for nu}
\NormalTok{  ns }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(y)}
\NormalTok{  nus }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(nu,}\AttributeTok{nrow=}\NormalTok{ns,}\AttributeTok{ncol=}\FunctionTok{length}\NormalTok{(nu),}\AttributeTok{byrow=}\NormalTok{T)}
  \CommentTok{\# y {-} nu}
\NormalTok{  y\_nu }\OtherTok{\textless{}{-}}\NormalTok{ y }\SpecialCharTok{{-}}\NormalTok{ nus}
  \CommentTok{\# f = inv(lambda)*(y{-}nu)}
\NormalTok{  F }\OtherTok{\textless{}{-}}\NormalTok{ lambda1 }\SpecialCharTok{\%*\%} \FunctionTok{t}\NormalTok{(}\FunctionTok{as.matrix}\NormalTok{(y\_nu))}
\NormalTok{\}}

\CommentTok{\# Load the cleaned csv file}

\CommentTok{\# load data}
\NormalTok{data}\OtherTok{\textless{}{-}}\FunctionTok{read.csv}\NormalTok{(}\StringTok{\textquotesingle{}Final\_COVIDiSTRESS\_Vol2\_cleaned.csv\textquotesingle{}}\NormalTok{)}

\CommentTok{\# item names to be aligned}
\NormalTok{items.pss }\OtherTok{\textless{}{-}} \FunctionTok{colnames}\NormalTok{(data)[}\DecValTok{45}\SpecialCharTok{:}\DecValTok{54}\NormalTok{]}
\NormalTok{items.sps }\OtherTok{\textless{}{-}} \FunctionTok{colnames}\NormalTok{(data)[}\DecValTok{76}\SpecialCharTok{:}\DecValTok{78}\NormalTok{]}
\NormalTok{items.identity }\OtherTok{\textless{}{-}} \FunctionTok{colnames}\NormalTok{(data)[}\DecValTok{173}\SpecialCharTok{:}\DecValTok{176}\NormalTok{]}
\NormalTok{items.resilience }\OtherTok{\textless{}{-}} \FunctionTok{colnames}\NormalTok{(data)[}\DecValTok{120}\SpecialCharTok{:}\DecValTok{125}\NormalTok{]}
\NormalTok{items.ps }\OtherTok{\textless{}{-}} \FunctionTok{colnames}\NormalTok{(data)[}\DecValTok{58}\SpecialCharTok{:}\DecValTok{61}\NormalTok{]}

\CommentTok{\# reverse coded items}
\NormalTok{data[,items.resilience[}\DecValTok{2}\NormalTok{]] }\OtherTok{\textless{}{-}} \DecValTok{8}\SpecialCharTok{{-}}\NormalTok{data[,items.resilience[}\DecValTok{2}\NormalTok{]]}
\NormalTok{data[,items.resilience[}\DecValTok{4}\NormalTok{]] }\OtherTok{\textless{}{-}} \DecValTok{8}\SpecialCharTok{{-}}\NormalTok{data[,items.resilience[}\DecValTok{4}\NormalTok{]]}
\NormalTok{data[,items.resilience[}\DecValTok{6}\NormalTok{]] }\OtherTok{\textless{}{-}} \DecValTok{8}\SpecialCharTok{{-}}\NormalTok{data[,items.resilience[}\DecValTok{6}\NormalTok{]]}

\CommentTok{\# extract languages with n \textgreater{}= 100}
\NormalTok{n.langs }\OtherTok{\textless{}{-}} \FunctionTok{table}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{UserLanguage)}
\NormalTok{list.langs }\OtherTok{\textless{}{-}} \FunctionTok{labels}\NormalTok{(n.langs)[[}\DecValTok{1}\NormalTok{]]}
\NormalTok{langs.include }\OtherTok{\textless{}{-}}\NormalTok{ list.langs[n.langs}\SpecialCharTok{\textgreater{}=}\DecValTok{100}\NormalTok{]}
\NormalTok{n.include }\OtherTok{\textless{}{-}}\NormalTok{ n.langs[n.langs}\SpecialCharTok{\textgreater{}=}\DecValTok{100}\NormalTok{]}

\CommentTok{\# extract data}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(langs.include))\{}
  \ControlFlowTok{if}\NormalTok{ (i }\SpecialCharTok{==} \DecValTok{1}\NormalTok{)\{}
\NormalTok{    data.mi }\OtherTok{\textless{}{-}}\NormalTok{ data[data}\SpecialCharTok{$}\NormalTok{UserLanguage }\SpecialCharTok{==}\NormalTok{ langs.include[i],]}
\NormalTok{  \}}\ControlFlowTok{else}\NormalTok{\{}
\NormalTok{    current }\OtherTok{\textless{}{-}}\NormalTok{ data[data}\SpecialCharTok{$}\NormalTok{UserLanguage }\SpecialCharTok{==}\NormalTok{ langs.include[i],]}
\NormalTok{    data.mi }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(data.mi,current)}
\NormalTok{  \}}
\NormalTok{\}}

\CommentTok{\# set and examine fitmeasures}
\NormalTok{fits }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}rmsea.scaled\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}srmr\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}cfi.scaled\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}tli.scaled\textquotesingle{}}\NormalTok{)}

\DocumentationTok{\#\#\#\#\#}
\CommentTok{\# 1. PSS}

\CommentTok{\# general CFA: PSS}
\NormalTok{cfa.model.pss }\OtherTok{\textless{}{-}} \StringTok{\textquotesingle{}PSS =\textasciitilde{} perceived\_stress\_sca\_1 + perceived\_stress\_sca\_2+}
\StringTok{  perceived\_stress\_sca\_3 + perceived\_stress\_sca\_4 + perceived\_stress\_sca\_5+}
\StringTok{  perceived\_stress\_sca\_6 + perceived\_stress\_sca\_7 + perceived\_stress\_sca\_8+}
\StringTok{  perceived\_stress\_sca\_9 + perceived\_stress\_sca\_10\textquotesingle{}}
\NormalTok{cfa.whole.pss }\OtherTok{\textless{}{-}} \FunctionTok{cfa}\NormalTok{(}\AttributeTok{model=}\NormalTok{cfa.model.pss,}\AttributeTok{data=}\NormalTok{data.mi,}\AttributeTok{estimator=}\StringTok{\textquotesingle{}WLSMV\textquotesingle{}}\NormalTok{, }\AttributeTok{group =} 
                       \StringTok{\textquotesingle{}UserLanguage\textquotesingle{}}\NormalTok{)}
\FunctionTok{fitMeasures}\NormalTok{(cfa.whole.pss)[fits]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## rmsea.scaled         srmr   cfi.scaled   tli.scaled 
##   0.09464355   0.06379443   0.87413322   0.83817129
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# msea.scaled         srmr   cfi.scaled   tli.scaled }
\CommentTok{\#  0.09464355   0.06379443   0.87413322   0.83817129 }
\CommentTok{\# not good {-}\textgreater{} alignment}

\CommentTok{\# measurement alignment test}
\CommentTok{\# extract parameters}
\NormalTok{par.pss }\OtherTok{\textless{}{-}} \FunctionTok{invariance\_alignment\_cfa\_config}\NormalTok{(}\AttributeTok{dat =}\NormalTok{ data.mi[,items.pss], }
                                       \AttributeTok{group =}\NormalTok{ data.mi}\SpecialCharTok{$}\NormalTok{UserLanguage)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Compute CFA for group 1
## Compute CFA for group 2
## Compute CFA for group 3
## Compute CFA for group 4
## Compute CFA for group 5
## Compute CFA for group 6
## Compute CFA for group 7
## Compute CFA for group 8
## Compute CFA for group 9
## Compute CFA for group 10
## Compute CFA for group 11
## Compute CFA for group 12
## Compute CFA for group 13
## Compute CFA for group 14
## Compute CFA for group 15
## Compute CFA for group 16
## Compute CFA for group 17
## Compute CFA for group 18
## Compute CFA for group 19
## Compute CFA for group 20
## Compute CFA for group 21
## Compute CFA for group 22
## Compute CFA for group 23
## Compute CFA for group 24
## Compute CFA for group 25
## Compute CFA for group 26
## Compute CFA for group 27
## Compute CFA for group 28
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# do alignment}
\NormalTok{mod1.pss }\OtherTok{\textless{}{-}} \FunctionTok{invariance.alignment}\NormalTok{(}\AttributeTok{lambda =}\NormalTok{ par.pss}\SpecialCharTok{$}\NormalTok{lambda, }\AttributeTok{nu =}
\NormalTok{                                   par.pss}\SpecialCharTok{$}\NormalTok{nu, }\AttributeTok{align.scale =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.2}\NormalTok{, }\FloatTok{0.4}\NormalTok{), }\AttributeTok{align.pow =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.25}\NormalTok{, }\FloatTok{0.25}\NormalTok{))}
\CommentTok{\# test performance}
\NormalTok{mod1.pss}\SpecialCharTok{$}\NormalTok{es.invariance[}\StringTok{\textquotesingle{}R2\textquotesingle{}}\NormalTok{,]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   loadings intercepts 
##  0.9850629  0.9930655
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#loadings intercepts }
\CommentTok{\#0.9850629  0.9930655  Very good}


\DocumentationTok{\#\#\#\#\#}
\CommentTok{\# 2. sps}

\CommentTok{\# general CFA: sps}
\NormalTok{cfa.model.sps }\OtherTok{\textless{}{-}} \StringTok{\textquotesingle{}SPS =\textasciitilde{} perceived\_support\_1\_midneutral + }
\StringTok{  perceived\_support\_2\_midneutral+perceived\_support\_3\_midneutral\textquotesingle{}}
\NormalTok{cfa.whole.sps }\OtherTok{\textless{}{-}} \FunctionTok{cfa}\NormalTok{(}\AttributeTok{model=}\NormalTok{cfa.model.sps,}\AttributeTok{data=}\NormalTok{data.mi,}\AttributeTok{estimator=}\StringTok{\textquotesingle{}WLSMV\textquotesingle{}}\NormalTok{, }\AttributeTok{group =} 
                       \StringTok{\textquotesingle{}UserLanguage\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning in lav_object_post_check(object): lavaan WARNING: some estimated ov
## variances are negative
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{fitMeasures}\NormalTok{(cfa.whole.sps)[fits]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## rmsea.scaled         srmr   cfi.scaled   tli.scaled 
##  0.00000e+00  8.35017e-08  1.00000e+00  1.00000e+00
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# msea.scaled         srmr   cfi.scaled   tli.scaled }
\CommentTok{\#  0.00000e+00  8.35017e{-}08  1.00000e+00  1.00000e+00 }
\CommentTok{\# good {-}\textgreater{} metric}

\NormalTok{cfa.metric.sps }\OtherTok{\textless{}{-}} \FunctionTok{cfa}\NormalTok{(}\AttributeTok{model=}\NormalTok{cfa.model.sps,}\AttributeTok{data=}\NormalTok{data.mi,}\AttributeTok{estimator=}\StringTok{\textquotesingle{}WLSMV\textquotesingle{}}\NormalTok{, }\AttributeTok{group =} 
                        \StringTok{\textquotesingle{}UserLanguage\textquotesingle{}}\NormalTok{, }\AttributeTok{group.equal=}\StringTok{\textquotesingle{}loadings\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning in lav_object_post_check(object): lavaan WARNING: some estimated ov
## variances are negative
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{fitMeasures}\NormalTok{(cfa.metric.sps)[fits]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## rmsea.scaled         srmr   cfi.scaled   tli.scaled 
##   0.05463580   0.02031403   0.98934654   0.98342795
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# msea.scaled         srmr   cfi.scaled   tli.scaled }
\CommentTok{\#    0.05463580   0.02031403   0.98934654   0.98342795 }
\CommentTok{\# not acceptable due to huge fit indicator change {-}\textgreater{} alignment}

\CommentTok{\# measurement alignment test}
\CommentTok{\# extract parameters}
\NormalTok{par.sps }\OtherTok{\textless{}{-}} \FunctionTok{invariance\_alignment\_cfa\_config}\NormalTok{(}\AttributeTok{dat =}\NormalTok{ data.mi[,items.sps], }
                                           \AttributeTok{group =}\NormalTok{ data.mi}\SpecialCharTok{$}\NormalTok{UserLanguage)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Compute CFA for group 1
\end{verbatim}

\begin{verbatim}
## Warning in lav_object_post_check(object): lavaan WARNING: some estimated ov
## variances are negative
\end{verbatim}

\begin{verbatim}
## Compute CFA for group 2
## Compute CFA for group 3
## Compute CFA for group 4
## Compute CFA for group 5
## Compute CFA for group 6
## Compute CFA for group 7
## Compute CFA for group 8
## Compute CFA for group 9
## Compute CFA for group 10
## Compute CFA for group 11
## Compute CFA for group 12
## Compute CFA for group 13
## Compute CFA for group 14
## Compute CFA for group 15
## Compute CFA for group 16
## Compute CFA for group 17
## Compute CFA for group 18
## Compute CFA for group 19
## Compute CFA for group 20
## Compute CFA for group 21
## Compute CFA for group 22
## Compute CFA for group 23
## Compute CFA for group 24
## Compute CFA for group 25
## Compute CFA for group 26
## Compute CFA for group 27
## Compute CFA for group 28
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# do alignment}
\NormalTok{mod1.sps }\OtherTok{\textless{}{-}} \FunctionTok{invariance.alignment}\NormalTok{(}\AttributeTok{lambda =}\NormalTok{ par.sps}\SpecialCharTok{$}\NormalTok{lambda, }\AttributeTok{nu =}
\NormalTok{                                   par.sps}\SpecialCharTok{$}\NormalTok{nu, }\AttributeTok{align.scale =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.2}\NormalTok{, }\FloatTok{0.4}\NormalTok{), }\AttributeTok{align.pow =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.25}\NormalTok{, }\FloatTok{0.25}\NormalTok{))}
\CommentTok{\# test performance}
\NormalTok{mod1.sps}\SpecialCharTok{$}\NormalTok{es.invariance[}\StringTok{\textquotesingle{}R2\textquotesingle{}}\NormalTok{,]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   loadings intercepts 
##  0.9924918  0.9987810
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#loadings intercepts }
\CommentTok{\# 0.9924918  0.9987810   Very good}


\DocumentationTok{\#\#\#\#\#}
\CommentTok{\# 3. identity}


\CommentTok{\# general CFA: identity}
\NormalTok{cfa.model.identity }\OtherTok{\textless{}{-}} \StringTok{\textquotesingle{}Identity =\textasciitilde{} identity\_1\_0neutral + identity\_2\_0neutral+}
\StringTok{  identity\_3\_0neutral+identity\_4\_0neutral\textquotesingle{}}
\NormalTok{cfa.whole.identity}\OtherTok{\textless{}{-}} \FunctionTok{cfa}\NormalTok{(}\AttributeTok{model=}\NormalTok{cfa.model.identity,}\AttributeTok{data=}\NormalTok{data.mi,}\AttributeTok{estimator=}\StringTok{\textquotesingle{}WLSMV\textquotesingle{}}\NormalTok{, }\AttributeTok{group =} 
                       \StringTok{\textquotesingle{}UserLanguage\textquotesingle{}}\NormalTok{)}
\FunctionTok{fitMeasures}\NormalTok{(cfa.whole.identity)[fits]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## rmsea.scaled         srmr   cfi.scaled   tli.scaled 
##   0.10233495   0.03053738   0.96461385   0.89384156
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# msea.scaled         srmr   cfi.scaled   tli.scaled }
\CommentTok{\#  0.10233495   0.03053738   0.96461385   0.89384156}

\CommentTok{\# measurement alignment test}
\CommentTok{\# extract parameters}
\NormalTok{par.identity }\OtherTok{\textless{}{-}} \FunctionTok{invariance\_alignment\_cfa\_config}\NormalTok{(}\AttributeTok{dat =}\NormalTok{ data.mi[,items.identity], }
                                           \AttributeTok{group =}\NormalTok{ data.mi}\SpecialCharTok{$}\NormalTok{UserLanguage)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Compute CFA for group 1
## Compute CFA for group 2
## Compute CFA for group 3
## Compute CFA for group 4
## Compute CFA for group 5
## Compute CFA for group 6
## Compute CFA for group 7
## Compute CFA for group 8
## Compute CFA for group 9
## Compute CFA for group 10
## Compute CFA for group 11
## Compute CFA for group 12
## Compute CFA for group 13
## Compute CFA for group 14
## Compute CFA for group 15
## Compute CFA for group 16
## Compute CFA for group 17
## Compute CFA for group 18
## Compute CFA for group 19
## Compute CFA for group 20
## Compute CFA for group 21
## Compute CFA for group 22
## Compute CFA for group 23
## Compute CFA for group 24
## Compute CFA for group 25
## Compute CFA for group 26
## Compute CFA for group 27
## Compute CFA for group 28
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# do alignment}
\NormalTok{mod1.identity }\OtherTok{\textless{}{-}} \FunctionTok{invariance.alignment}\NormalTok{(}\AttributeTok{lambda =}\NormalTok{ par.identity}\SpecialCharTok{$}\NormalTok{lambda, }\AttributeTok{nu =}
\NormalTok{                                        par.identity}\SpecialCharTok{$}\NormalTok{nu, }\AttributeTok{align.scale =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.2}\NormalTok{, }\FloatTok{0.4}\NormalTok{), }\AttributeTok{align.pow =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.25}\NormalTok{, }\FloatTok{0.25}\NormalTok{))}
\CommentTok{\# test performance}
\NormalTok{mod1.identity}\SpecialCharTok{$}\NormalTok{es.invariance[}\StringTok{\textquotesingle{}R2\textquotesingle{}}\NormalTok{,]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   loadings intercepts 
##  0.9516856  0.9923646
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#loadings intercepts }
\CommentTok{\# 0.9516856  0.9923646     good}


\DocumentationTok{\#\#\#\#\#}
\CommentTok{\# 4. resilience}


\CommentTok{\# general CFA: resilience}
\NormalTok{cfa.model.resilience }\OtherTok{\textless{}{-}} \StringTok{\textquotesingle{}Identity =\textasciitilde{} resilience\_1 + resilience\_2+resilience\_3+}
\StringTok{  resilience\_4+resilience\_5+resilience\_6\textquotesingle{}}
\NormalTok{cfa.whole.resilience}\OtherTok{\textless{}{-}} \FunctionTok{cfa}\NormalTok{(}\AttributeTok{model=}\NormalTok{cfa.model.resilience,}\AttributeTok{data=}\NormalTok{data.mi,}\AttributeTok{estimator=}\StringTok{\textquotesingle{}WLSMV\textquotesingle{}}\NormalTok{, }\AttributeTok{group =} 
                           \StringTok{\textquotesingle{}UserLanguage\textquotesingle{}}\NormalTok{)}
\FunctionTok{fitMeasures}\NormalTok{(cfa.whole.resilience)[fits]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## rmsea.scaled         srmr   cfi.scaled   tli.scaled 
##   0.09295767   0.03737383   0.95253039   0.92088398
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# msea.scaled         srmr   cfi.scaled   tli.scaled }
\CommentTok{\#  0.09295767   0.03737383   0.95253039   0.92088398 not good}

\CommentTok{\# measurement alignment test}
\CommentTok{\# extract parameters}
\NormalTok{par.resilience }\OtherTok{\textless{}{-}} \FunctionTok{invariance\_alignment\_cfa\_config}\NormalTok{(}\AttributeTok{dat =}\NormalTok{ data.mi[,items.resilience], }
                                                \AttributeTok{group =}\NormalTok{ data.mi}\SpecialCharTok{$}\NormalTok{UserLanguage)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Compute CFA for group 1
## Compute CFA for group 2
## Compute CFA for group 3
## Compute CFA for group 4
## Compute CFA for group 5
## Compute CFA for group 6
## Compute CFA for group 7
## Compute CFA for group 8
## Compute CFA for group 9
## Compute CFA for group 10
## Compute CFA for group 11
## Compute CFA for group 12
## Compute CFA for group 13
## Compute CFA for group 14
## Compute CFA for group 15
## Compute CFA for group 16
## Compute CFA for group 17
## Compute CFA for group 18
## Compute CFA for group 19
## Compute CFA for group 20
## Compute CFA for group 21
## Compute CFA for group 22
## Compute CFA for group 23
## Compute CFA for group 24
## Compute CFA for group 25
## Compute CFA for group 26
## Compute CFA for group 27
## Compute CFA for group 28
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# do alignment}
\NormalTok{mod1.resilience }\OtherTok{\textless{}{-}} \FunctionTok{invariance.alignment}\NormalTok{(}\AttributeTok{lambda =}\NormalTok{ par.resilience}\SpecialCharTok{$}\NormalTok{lambda, }\AttributeTok{nu =}
\NormalTok{                                        par.resilience}\SpecialCharTok{$}\NormalTok{nu, }\AttributeTok{align.scale =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.2}\NormalTok{, }\FloatTok{0.4}\NormalTok{), }\AttributeTok{align.pow =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.25}\NormalTok{, }\FloatTok{0.25}\NormalTok{))}
\CommentTok{\# test performance}
\NormalTok{mod1.resilience}\SpecialCharTok{$}\NormalTok{es.invariance[}\StringTok{\textquotesingle{}R2\textquotesingle{}}\NormalTok{,]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   loadings intercepts 
##  0.9799195  0.9971573
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#loadings intercepts }
\CommentTok{\# 0.9799195  0.9971573     good}


\DocumentationTok{\#\#\#\#\#}
\CommentTok{\# 5. primary stressor}
\NormalTok{cfa.model.ps }\OtherTok{\textless{}{-}} \StringTok{\textquotesingle{}PS =\textasciitilde{} primary\_stressors\_1 + primary\_stressors\_2+primary\_stressors\_3+}
\StringTok{  primary\_stressors\_4\textquotesingle{}}
\NormalTok{cfa.whole.ps}\OtherTok{\textless{}{-}} \FunctionTok{cfa}\NormalTok{(}\AttributeTok{model=}\NormalTok{cfa.model.ps,}\AttributeTok{data=}\NormalTok{data.mi,}\AttributeTok{estimator=}\StringTok{\textquotesingle{}WLSMV\textquotesingle{}}\NormalTok{, }\AttributeTok{group =} 
                             \StringTok{\textquotesingle{}UserLanguage\textquotesingle{}}\NormalTok{)}
\FunctionTok{fitMeasures}\NormalTok{(cfa.whole.ps)[fits]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## rmsea.scaled         srmr   cfi.scaled   tli.scaled 
##   0.32856328   0.09944144   0.70094630   0.10283891
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# msea.scaled         srmr   cfi.scaled   tli.scaled }
\CommentTok{\#  0.32856328   0.09944144   0.70094630   0.10283891  not good}

\CommentTok{\# measurement alignment test}
\CommentTok{\# extract parameters}
\NormalTok{par.ps }\OtherTok{\textless{}{-}} \FunctionTok{invariance\_alignment\_cfa\_config}\NormalTok{(}\AttributeTok{dat =}\NormalTok{ data.mi[,items.ps], }
                                                  \AttributeTok{group =}\NormalTok{ data.mi}\SpecialCharTok{$}\NormalTok{UserLanguage)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Compute CFA for group 1
## Compute CFA for group 2
## Compute CFA for group 3
## Compute CFA for group 4
\end{verbatim}

\begin{verbatim}
## Warning in lav_object_post_check(object): lavaan WARNING: some estimated ov
## variances are negative
\end{verbatim}

\begin{verbatim}
## Compute CFA for group 5
## Compute CFA for group 6
## Compute CFA for group 7
## Compute CFA for group 8
## Compute CFA for group 9
## Compute CFA for group 10
## Compute CFA for group 11
## Compute CFA for group 12
## Compute CFA for group 13
## Compute CFA for group 14
## Compute CFA for group 15
## Compute CFA for group 16
## Compute CFA for group 17
## Compute CFA for group 18
## Compute CFA for group 19
## Compute CFA for group 20
## Compute CFA for group 21
## Compute CFA for group 22
## Compute CFA for group 23
## Compute CFA for group 24
\end{verbatim}

\begin{verbatim}
## Warning in lav_object_post_check(object): lavaan WARNING: some estimated ov
## variances are negative
\end{verbatim}

\begin{verbatim}
## Compute CFA for group 25
## Compute CFA for group 26
## Compute CFA for group 27
## Compute CFA for group 28
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# do alignment}
\NormalTok{mod1.ps }\OtherTok{\textless{}{-}} \FunctionTok{invariance.alignment}\NormalTok{(}\AttributeTok{lambda =}\NormalTok{ par.ps}\SpecialCharTok{$}\NormalTok{lambda, }\AttributeTok{nu =}
\NormalTok{                                  par.ps}\SpecialCharTok{$}\NormalTok{nu, }\AttributeTok{align.scale =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.2}\NormalTok{, }\FloatTok{0.4}\NormalTok{), }\AttributeTok{align.pow =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.25}\NormalTok{, }\FloatTok{0.25}\NormalTok{))}
\CommentTok{\# test performance}
\NormalTok{mod1.ps}\SpecialCharTok{$}\NormalTok{es.invariance[}\StringTok{\textquotesingle{}R2\textquotesingle{}}\NormalTok{,]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   loadings intercepts 
##  0.9574455  0.9861105
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#loadings intercepts }
\CommentTok{\# 0.9574455  0.9861105     good}

\DocumentationTok{\#\#\#\#\#}
\CommentTok{\# factor score calculation}

\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(langs.include))\{}
  \ControlFlowTok{if}\NormalTok{ (i }\SpecialCharTok{==} \DecValTok{1}\NormalTok{)\{}
    \CommentTok{\# create new matrix}
\NormalTok{    data.aligned }\OtherTok{\textless{}{-}}\NormalTok{ data.mi[data.mi}\SpecialCharTok{$}\NormalTok{UserLanguage}\SpecialCharTok{==}\NormalTok{langs.include[i],]}
    \CommentTok{\# aligned factor score}
\NormalTok{    F.pss }\OtherTok{\textless{}{-}} \FunctionTok{aligned.factor.scores}\NormalTok{(mod1.pss}\SpecialCharTok{$}\NormalTok{lambda.aligned[i,],}
\NormalTok{                               mod1.pss}\SpecialCharTok{$}\NormalTok{nu.aligned[i,],}
\NormalTok{                               data.mi[data.mi}\SpecialCharTok{$}\NormalTok{UserLanguage}\SpecialCharTok{==}\NormalTok{langs.include[i],items.pss])}
\NormalTok{    F.sps }\OtherTok{\textless{}{-}} \FunctionTok{aligned.factor.scores}\NormalTok{(mod1.sps}\SpecialCharTok{$}\NormalTok{lambda.aligned[i,],}
\NormalTok{                                   mod1.sps}\SpecialCharTok{$}\NormalTok{nu.aligned[i,],}
\NormalTok{                                   data.mi[data.mi}\SpecialCharTok{$}\NormalTok{UserLanguage}\SpecialCharTok{==}\NormalTok{langs.include[i],items.sps])}
\NormalTok{    F.id }\OtherTok{\textless{}{-}} \FunctionTok{aligned.factor.scores}\NormalTok{(mod1.identity}\SpecialCharTok{$}\NormalTok{lambda.aligned[i,],}
\NormalTok{                                  mod1.identity}\SpecialCharTok{$}\NormalTok{nu.aligned[i,],}
\NormalTok{                                   data.mi[data.mi}\SpecialCharTok{$}\NormalTok{UserLanguage}\SpecialCharTok{==}\NormalTok{langs.include[i],items.identity])}
\NormalTok{    F.rs }\OtherTok{\textless{}{-}} \FunctionTok{aligned.factor.scores}\NormalTok{(mod1.resilience}\SpecialCharTok{$}\NormalTok{lambda.aligned[i,],}
\NormalTok{                                  mod1.resilience}\SpecialCharTok{$}\NormalTok{nu.aligned[i,],}
\NormalTok{                                  data.mi[data.mi}\SpecialCharTok{$}\NormalTok{UserLanguage}\SpecialCharTok{==}\NormalTok{langs.include[i],items.resilience])}
\NormalTok{    F.ps }\OtherTok{\textless{}{-}} \FunctionTok{aligned.factor.scores}\NormalTok{(mod1.ps}\SpecialCharTok{$}\NormalTok{lambda.aligned[i,],}
\NormalTok{                                  mod1.ps}\SpecialCharTok{$}\NormalTok{nu.aligned[i,],}
\NormalTok{                                  data.mi[data.mi}\SpecialCharTok{$}\NormalTok{UserLanguage}\SpecialCharTok{==}\NormalTok{langs.include[i],items.ps])}
\NormalTok{    data.aligned}\SpecialCharTok{$}\NormalTok{pss }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(F.pss)}
\NormalTok{    data.aligned}\SpecialCharTok{$}\NormalTok{sps }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(F.sps)}
\NormalTok{    data.aligned}\SpecialCharTok{$}\NormalTok{identity }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(F.id)}
\NormalTok{    data.aligned}\SpecialCharTok{$}\NormalTok{resilience }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(F.id)}
\NormalTok{    data.aligned}\SpecialCharTok{$}\NormalTok{primary\_stressor\_avg }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(F.ps)}
\NormalTok{  \}}\ControlFlowTok{else}
\NormalTok{  \{}
    \CommentTok{\# bind}
\NormalTok{    current }\OtherTok{\textless{}{-}}\NormalTok{ data.mi[data.mi}\SpecialCharTok{$}\NormalTok{UserLanguage}\SpecialCharTok{==}\NormalTok{langs.include[i],]}
\NormalTok{    F.pss }\OtherTok{\textless{}{-}} \FunctionTok{aligned.factor.scores}\NormalTok{(mod1.pss}\SpecialCharTok{$}\NormalTok{lambda.aligned[i,],}
\NormalTok{                                   mod1.pss}\SpecialCharTok{$}\NormalTok{nu.aligned[i,],}
\NormalTok{                               current[,items.pss])}
\NormalTok{    F.sps }\OtherTok{\textless{}{-}} \FunctionTok{aligned.factor.scores}\NormalTok{(mod1.sps}\SpecialCharTok{$}\NormalTok{lambda.aligned[i,],}
\NormalTok{                                   mod1.sps}\SpecialCharTok{$}\NormalTok{nu.aligned[i,],}
\NormalTok{                                   current[,items.sps])}
\NormalTok{    F.id }\OtherTok{\textless{}{-}} \FunctionTok{aligned.factor.scores}\NormalTok{(mod1.identity}\SpecialCharTok{$}\NormalTok{lambda.aligned[i,],}
\NormalTok{                                  mod1.identity}\SpecialCharTok{$}\NormalTok{nu.aligned[i,],}
\NormalTok{                                   current[,items.identity])}
\NormalTok{    F.rs }\OtherTok{\textless{}{-}} \FunctionTok{aligned.factor.scores}\NormalTok{(mod1.resilience}\SpecialCharTok{$}\NormalTok{lambda.aligned[i,],}
\NormalTok{                                  mod1.resilience}\SpecialCharTok{$}\NormalTok{nu.aligned[i,],}
\NormalTok{                                  current[,items.resilience])}
\NormalTok{    F.ps }\OtherTok{\textless{}{-}} \FunctionTok{aligned.factor.scores}\NormalTok{(mod1.ps}\SpecialCharTok{$}\NormalTok{lambda.aligned[i,],}
\NormalTok{                                  mod1.ps}\SpecialCharTok{$}\NormalTok{nu.aligned[i,],}
\NormalTok{                                  current[,items.ps])}
\NormalTok{    current}\SpecialCharTok{$}\NormalTok{pss }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(F.pss)}
\NormalTok{    current}\SpecialCharTok{$}\NormalTok{sps }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(F.sps)}
\NormalTok{    current}\SpecialCharTok{$}\NormalTok{identity }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(F.id)}
\NormalTok{    current}\SpecialCharTok{$}\NormalTok{resilience }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(F.rs)}
\NormalTok{    current}\SpecialCharTok{$}\NormalTok{primary\_stressor\_avg }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(F.ps)}
\NormalTok{    data.aligned }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(data.aligned,current)}
\NormalTok{  \}}
\NormalTok{\}}

\CommentTok{\# save aligned datafile}
\FunctionTok{save.image}\NormalTok{(}\AttributeTok{file=}\StringTok{\textquotesingle{}Stress\_aligned.RData\textquotesingle{}}\NormalTok{)}


\CommentTok{\# alphas}
\NormalTok{psych}\SpecialCharTok{::}\FunctionTok{alpha}\NormalTok{(data[,items.pss],}\AttributeTok{check.keys=}\ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning in psych::alpha(data[, items.pss], check.keys = TRUE): Some items were negatively correlated with total scale and were automatically reversed.
##  This is indicated by a negative sign for the variable name.
\end{verbatim}

\begin{verbatim}
## 
## Reliability analysis   
## Call: psych::alpha(x = data[, items.pss], check.keys = TRUE)
## 
##   raw_alpha std.alpha G6(smc) average_r S/N    ase mean   sd median_r
##       0.87      0.87    0.88       0.4 6.7 0.0015  1.9 0.69      0.4
## 
##  lower alpha upper     95% confidence boundaries
## 0.87 0.87 0.87 
## 
##  Reliability if an item is dropped:
##                         raw_alpha std.alpha G6(smc) average_r S/N alpha se
## perceived_stress_sca_1       0.86      0.86    0.86      0.40 6.0   0.0017
## perceived_stress_sca_2       0.85      0.85    0.86      0.39 5.7   0.0018
## perceived_stress_sca_3       0.85      0.85    0.86      0.39 5.8   0.0017
## perceived_stress_sca_4-      0.87      0.87    0.87      0.42 6.5   0.0015
## perceived_stress_sca_5-      0.86      0.86    0.87      0.41 6.2   0.0016
## perceived_stress_sca_6       0.86      0.86    0.87      0.40 6.1   0.0017
## perceived_stress_sca_7-      0.87      0.87    0.87      0.42 6.5   0.0016
## perceived_stress_sca_8-      0.86      0.86    0.86      0.40 6.1   0.0016
## perceived_stress_sca_9       0.86      0.86    0.87      0.40 6.1   0.0017
## perceived_stress_sca_10      0.85      0.85    0.86      0.38 5.5   0.0018
##                         var.r med.r
## perceived_stress_sca_1  0.013  0.38
## perceived_stress_sca_2  0.015  0.38
## perceived_stress_sca_3  0.014  0.38
## perceived_stress_sca_4- 0.014  0.41
## perceived_stress_sca_5- 0.017  0.41
## perceived_stress_sca_6  0.016  0.38
## perceived_stress_sca_7- 0.016  0.41
## perceived_stress_sca_8- 0.017  0.40
## perceived_stress_sca_9  0.015  0.38
## perceived_stress_sca_10 0.015  0.36
## 
##  Item statistics 
##                             n raw.r std.r r.cor r.drop mean   sd
## perceived_stress_sca_1  15715  0.70  0.68  0.65   0.60  1.9 1.03
## perceived_stress_sca_2  15697  0.76  0.75  0.73   0.68  1.9 1.11
## perceived_stress_sca_3  15705  0.75  0.74  0.71   0.67  2.4 1.08
## perceived_stress_sca_4- 15694  0.58  0.59  0.53   0.47  1.5 0.97
## perceived_stress_sca_5- 15701  0.63  0.64  0.60   0.54  1.9 0.92
## perceived_stress_sca_6  15699  0.68  0.67  0.62   0.59  2.0 0.99
## perceived_stress_sca_7- 15694  0.57  0.59  0.52   0.47  1.6 0.90
## perceived_stress_sca_8- 15690  0.66  0.67  0.62   0.56  1.8 0.95
## perceived_stress_sca_9  15697  0.67  0.67  0.62   0.58  2.1 1.01
## perceived_stress_sca_10 15691  0.79  0.78  0.77   0.72  1.7 1.11
## 
## Non missing response frequency for each item
##                            0    1    2    3    4 miss
## perceived_stress_sca_1  0.08 0.25 0.40 0.19 0.08    0
## perceived_stress_sca_2  0.10 0.25 0.36 0.19 0.09    0
## perceived_stress_sca_3  0.05 0.16 0.36 0.27 0.17    0
## perceived_stress_sca_4  0.03 0.12 0.35 0.36 0.15    0
## perceived_stress_sca_5  0.04 0.18 0.44 0.28 0.06    0
## perceived_stress_sca_6  0.07 0.25 0.42 0.20 0.07    0
## perceived_stress_sca_7  0.02 0.11 0.39 0.37 0.11    0
## perceived_stress_sca_8  0.04 0.18 0.40 0.31 0.07    0
## perceived_stress_sca_9  0.06 0.22 0.40 0.23 0.08    0
## perceived_stress_sca_10 0.15 0.30 0.33 0.15 0.07    0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{psych}\SpecialCharTok{::}\FunctionTok{alpha}\NormalTok{(data[,items.sps],}\AttributeTok{check.keys=}\ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Reliability analysis   
## Call: psych::alpha(x = data[, items.sps], check.keys = TRUE)
## 
##   raw_alpha std.alpha G6(smc) average_r S/N   ase mean  sd median_r
##       0.86      0.86    0.82      0.68 6.3 0.002  5.1 1.4     0.66
## 
##  lower alpha upper     95% confidence boundaries
## 0.86 0.86 0.86 
## 
##  Reliability if an item is dropped:
##                                raw_alpha std.alpha G6(smc) average_r S/N
## perceived_support_1_midneutral      0.87      0.87    0.77      0.77 6.6
## perceived_support_2_midneutral      0.75      0.75    0.60      0.60 3.0
## perceived_support_3_midneutral      0.79      0.80    0.66      0.66 3.9
##                                alpha se var.r med.r
## perceived_support_1_midneutral   0.0021    NA  0.77
## perceived_support_2_midneutral   0.0040    NA  0.60
## perceived_support_3_midneutral   0.0033    NA  0.66
## 
##  Item statistics 
##                                    n raw.r std.r r.cor r.drop mean  sd
## perceived_support_1_midneutral 15712  0.86  0.85  0.71   0.67  5.1 1.7
## perceived_support_2_midneutral 15710  0.91  0.91  0.87   0.80  5.2 1.6
## perceived_support_3_midneutral 15703  0.89  0.89  0.82   0.75  4.9 1.6
## 
## Non missing response frequency for each item
##                                   1    2    3    4    5    6    7 miss
## perceived_support_1_midneutral 0.05 0.07 0.08 0.11 0.19 0.31 0.20    0
## perceived_support_2_midneutral 0.03 0.05 0.07 0.12 0.20 0.33 0.19    0
## perceived_support_3_midneutral 0.04 0.07 0.09 0.13 0.23 0.29 0.15    0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{psych}\SpecialCharTok{::}\FunctionTok{alpha}\NormalTok{(data[,items.identity],}\AttributeTok{check.keys=}\ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Reliability analysis   
## Call: psych::alpha(x = data[, items.identity], check.keys = TRUE)
## 
##   raw_alpha std.alpha G6(smc) average_r S/N    ase mean  sd median_r
##       0.71      0.71    0.66      0.38 2.5 0.0037  3.4 1.4     0.37
## 
##  lower alpha upper     95% confidence boundaries
## 0.7 0.71 0.72 
## 
##  Reliability if an item is dropped:
##                     raw_alpha std.alpha G6(smc) average_r S/N alpha se  var.r
## identity_1_0neutral      0.69      0.69    0.60      0.42 2.2   0.0043 0.0048
## identity_2_0neutral      0.63      0.63    0.55      0.37 1.7   0.0050 0.0093
## identity_3_0neutral      0.61      0.61    0.52      0.35 1.6   0.0054 0.0024
## identity_4_0neutral      0.66      0.66    0.57      0.39 1.9   0.0047 0.0042
##                     med.r
## identity_1_0neutral  0.45
## identity_2_0neutral  0.32
## identity_3_0neutral  0.35
## identity_4_0neutral  0.40
## 
##  Item statistics 
##                         n raw.r std.r r.cor r.drop mean  sd
## identity_1_0neutral 15678  0.67  0.69  0.51   0.43  4.2 1.8
## identity_2_0neutral 15623  0.74  0.75  0.62   0.52  3.1 1.9
## identity_3_0neutral 15613  0.77  0.77  0.66   0.56  3.1 2.0
## identity_4_0neutral 15607  0.74  0.72  0.58   0.49  3.4 2.1
## 
## Non missing response frequency for each item
##                        0    1    2    3    4    5    6 miss
## identity_1_0neutral 0.10 0.03 0.04 0.06 0.16 0.36 0.25 0.00
## identity_2_0neutral 0.21 0.03 0.09 0.11 0.27 0.23 0.05 0.01
## identity_3_0neutral 0.22 0.03 0.09 0.12 0.25 0.23 0.05 0.01
## identity_4_0neutral 0.22 0.02 0.05 0.08 0.20 0.29 0.13 0.01
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{psych}\SpecialCharTok{::}\FunctionTok{alpha}\NormalTok{(data[,items.resilience],}\AttributeTok{check.keys=}\ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Reliability analysis   
## Call: psych::alpha(x = data[, items.resilience], check.keys = TRUE)
## 
##   raw_alpha std.alpha G6(smc) average_r S/N    ase mean  sd median_r
##       0.87      0.87    0.86      0.52 6.6 0.0016  4.3 1.2     0.51
## 
##  lower alpha upper     95% confidence boundaries
## 0.87 0.87 0.87 
## 
##  Reliability if an item is dropped:
##              raw_alpha std.alpha G6(smc) average_r S/N alpha se  var.r med.r
## resilience_1      0.85      0.85    0.83      0.53 5.6   0.0019 0.0056  0.51
## resilience_2      0.85      0.85    0.83      0.53 5.6   0.0019 0.0037  0.51
## resilience_3      0.85      0.85    0.83      0.53 5.7   0.0019 0.0055  0.50
## resilience_4      0.84      0.84    0.82      0.51 5.3   0.0020 0.0024  0.51
## resilience_5      0.85      0.85    0.83      0.54 5.8   0.0019 0.0058  0.54
## resilience_6      0.83      0.83    0.81      0.50 5.0   0.0021 0.0029  0.49
## 
##  Item statistics 
##                  n raw.r std.r r.cor r.drop mean  sd
## resilience_1 13283  0.76  0.76  0.70   0.65  4.9 1.5
## resilience_2 13279  0.78  0.77  0.71   0.66  4.2 1.6
## resilience_3 13283  0.76  0.76  0.68   0.63  4.3 1.6
## resilience_4 13274  0.80  0.80  0.76   0.70  4.2 1.6
## resilience_5 13274  0.74  0.75  0.67   0.62  4.2 1.5
## resilience_6 13274  0.83  0.83  0.79   0.74  4.3 1.6
## 
## Non missing response frequency for each item
##                 1    2    3    4    5    6    7 miss
## resilience_1 0.02 0.06 0.11 0.11 0.26 0.31 0.12 0.16
## resilience_2 0.04 0.13 0.22 0.14 0.19 0.20 0.06 0.16
## resilience_3 0.04 0.13 0.19 0.15 0.22 0.22 0.06 0.16
## resilience_4 0.04 0.13 0.23 0.14 0.19 0.20 0.06 0.16
## resilience_5 0.03 0.12 0.20 0.18 0.24 0.18 0.05 0.16
## resilience_6 0.04 0.11 0.20 0.16 0.21 0.23 0.06 0.16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{psych}\SpecialCharTok{::}\FunctionTok{alpha}\NormalTok{(data[,items.ps],}\AttributeTok{check.keys=}\ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Reliability analysis   
## Call: psych::alpha(x = data[, items.ps], check.keys = TRUE)
## 
##   raw_alpha std.alpha G6(smc) average_r S/N    ase mean sd median_r
##       0.69      0.69     0.7      0.36 2.2 0.0042  1.9  1     0.34
## 
##  lower alpha upper     95% confidence boundaries
## 0.68 0.69 0.7 
## 
##  Reliability if an item is dropped:
##                     raw_alpha std.alpha G6(smc) average_r S/N alpha se var.r
## primary_stressors_1      0.61      0.61    0.55      0.34 1.5   0.0054 0.029
## primary_stressors_2      0.59      0.59    0.52      0.32 1.4   0.0057 0.027
## primary_stressors_3      0.71      0.71    0.66      0.45 2.4   0.0042 0.038
## primary_stressors_4      0.59      0.60    0.59      0.33 1.5   0.0059 0.087
##                     med.r
## primary_stressors_1  0.37
## primary_stressors_2  0.30
## primary_stressors_3  0.37
## primary_stressors_4  0.17
## 
##  Item statistics 
##                         n raw.r std.r r.cor r.drop mean  sd
## primary_stressors_1 15496  0.74  0.74  0.66   0.50  1.6 1.4
## primary_stressors_2 15545  0.76  0.76  0.70   0.53  2.3 1.4
## primary_stressors_3 15309  0.64  0.63  0.44   0.34  1.6 1.5
## primary_stressors_4 15338  0.76  0.75  0.62   0.53  2.0 1.4
## 
## Non missing response frequency for each item
##                        0    1    2    3    4 miss
## primary_stressors_1 0.26 0.27 0.17 0.17 0.13 0.02
## primary_stressors_2 0.12 0.21 0.19 0.21 0.27 0.01
## primary_stressors_3 0.34 0.20 0.16 0.15 0.15 0.03
## primary_stressors_4 0.20 0.21 0.19 0.20 0.20 0.03
\end{verbatim}

\end{document}
